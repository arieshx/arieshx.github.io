---
layout: post
title: 不同的卷积方式总结
category: 深度学习
description: 不同的卷积方式总结
---

## 普通卷积

vgg,Alexnet等网络都是

## 深度可分离卷积 （**“DepthWise convolution”**）

![img](https://pic2.zhimg.com/80/v2-064bc45965c8af7101f11847d36e4b2d_hd.jpg)

问题在于，为什么一定要同时考虑图像区域和通道？我们为什么不能把通道和空间区域分开考虑？

我们首先对每一个通道进行各自的卷积操作，有多少个通道就有多少个过滤器。得到新的通道feature maps之后，这时再对这批新的通道feature maps进行标准的1×1跨通道卷积操作。这种操作被称为**“DepthWise convolution”**，缩写“DW”。

**减少参数**

这种操作是相当有效的，在imagenet 1000类分类任务中已经超过了InceptionV3的表现，而且也同时减少了大量的参数，我们来算一算，假设输入通道数为3，要求输出通道数为256，两种做法：

1.直接接一个3×3×256的卷积核，参数量为：3×3×3×256 = 6,912

2.DW操作，分两步完成，参数量为：3×3×3 + 3×1×1×256 = 795，又把参数量降低到九分之一！

因此，一个depthwise操作比标准的卷积操作降低不少的参数量，同时论文中指出这个模型得到了更好的分类效果。

**具体分类**

更详细的操作说明：将depthwise separable convolution分成两步，一步叫depthwise convolution，就是下图的（b），另一步是pointwise convolution，就是下图的（c）。

假设原来是3*3的卷积，那么depthwise separable convolution就是先用M个3*3卷积核一对一卷积输入的M个feature map，不求和，生成M个结果；然后用N个1*1的卷积核正常卷积前面生成的M个结果，求和，最后生成N个结果

![img](https://pic3.zhimg.com/80/v2-f95469b1722acb7feaad0a0d774a5c32_hd.jpg)

**DW的应用**

