---
layout: post
title: 不同的卷积方式总结
category: 深度学习
description: 不同的卷积方式总结
---

## 普通卷积

vgg,Alexnet等网络都是

## 深度可分离卷积 （**“DepthWise convolution”**）

![img](https://pic2.zhimg.com/80/v2-064bc45965c8af7101f11847d36e4b2d_hd.jpg)

问题在于，为什么一定要同时考虑图像区域和通道？我们为什么不能把通道和空间区域分开考虑？

我们首先对每一个通道进行各自的卷积操作，有多少个通道就有多少个过滤器。得到新的通道feature maps之后，这时再对这批新的通道feature maps进行标准的1×1跨通道卷积操作。这种操作被称为**“DepthWise convolution”**，缩写“DW”。

**减少参数**

这种操作是相当有效的，在imagenet 1000类分类任务中已经超过了InceptionV3的表现，而且也同时减少了大量的参数，我们来算一算，假设输入通道数为3，要求输出通道数为256，两种做法：

1.直接接一个3×3×256的卷积核，参数量为：3×3×3×256 = 6,912

2.DW操作，分两步完成，参数量为：3×3×3 + 3×1×1×256 = 795，又把参数量降低到九分之一！

因此，一个depthwise操作比标准的卷积操作降低不少的参数量，同时论文中指出这个模型得到了更好的分类效果。

**具体操作**

更详细的操作说明：将depthwise separable convolution分成两步，一步叫depthwise convolution，就是下图的（b），另一步是pointwise convolution，就是下图的（c）。

假设原来是3*3的卷积，那么depthwise separable convolution就是先用M个3*3卷积核一对一卷积输入的M个feature map，不求和，生成M个结果；然后用N个1*1的卷积核正常卷积前面生成的M个结果，求和，最后生成N个结果

![img](https://pic3.zhimg.com/80/v2-f95469b1722acb7feaad0a0d774a5c32_hd.jpg)

**DW的应用**

1. Xception是google继Inception后提出的对Inception v3的另一种改进，主要是采用depthwise separable convolution来替换原来Inception v3中的卷积操作
2. MobileNet 是Google推出的一款高效的移动端轻量化网络，其核心即是深度可分离卷积。主要作用是极大的减少参数量。

## 分组卷积（Group convolution）

Group convolution 分组卷积，最早在AlexNet中出现，由于当时的硬件资源有限，训练AlexNet时卷积操作不能全部放在同一个GPU处理，因此作者把feature maps分给多个GPU分别进行处理，最后把多个GPU的结果进行融合。

在说明分组卷积之前我们用一张图来体会一下一般的卷积操作。

![img](https://pic4.zhimg.com/80/v2-cfd04a4b79abd141492c96ee9bf4506b_hd.jpg)

从上图可以看出，一般的卷积会对输入数据的整体一起做卷积操作，即输入数据：H1×W1×C1；而卷积核大小为h1×w1，一共有C2个，然后卷积得到的输出数据就是H2×W2×C2。这里我们假设输出和输出的分辨率是不变的。主要看这个过程是一气呵成的，这对于存储器的容量提出了更高的要求。 但是分组卷积明显就没有那么多的参数。先用图片直观地感受一下分组卷积的过程。对于上面所说的同样的一个问题，分组卷积就如下图所示。

![img](https://pic1.zhimg.com/80/v2-e081eef92002e1bdab900d9aa14691e0_hd.jpg)

可以看到，图中将输入数据分成了2组（组数为g），需要注意的是，这种分组只是在深度上进行划分，即某几个通道编为一组，这个具体的数量由（C1/g）决定。因为输出数据的改变，相应的，卷积核也需要做出同样的改变。即每组中卷积核的深度也就变成了（C1/g），而卷积核的大小是不需要改变的，此时每组的卷积核的个数就变成了（C2/g）个，而不是原来的C2了。然后用每组的卷积核同它们对应组内的输入数据卷积，得到了输出数据以后，再用concatenate的方式组合起来，最终的输出数据的通道仍旧是C2。也就是说，分组数g决定以后，那么我们将并行的运算g个相同的卷积过程，每个过程里（每组），输入数据为H1×W1×C1/g，卷积核大小为h1×w1×C1/g，一共有C2/g个，输出数据为H2×W2×C2/g。 **例子** 从一个具体的例子来看，Group conv本身就极大地减少了参数。比如当输入通道为256，输出通道也为256，kernel size为3×3，不做Group conv参数为256×3×3×256。实施分组卷积时，若group为8，每个group的input channel和output channel均为32，参数为8×32×3×3×32，是原来的八分之一。而Group conv最后每一组输出的feature maps应该是以concatenate的方式组合。 Alex认为group conv的方式能够增加 filter之间的对角相关性，而且能够减少训练参数，不容易过拟合，这类似于正则的效果。

**作用**：

1 **减少参数量**，分成 ![[公式]](https://www.zhihu.com/equation?tex=G) 组，则该层的参数量减少为原来的 ![[公式]](https://www.zhihu.com/equation?tex=%5Cfrac%7B1%7D%7BG%7D)

2 在减少训练参数的情况下，可以认为模型复杂度降低，起到了正则的作用

3 当分组数量等于输入通道数量时，分组卷积就像是深度可分离卷积的第一步，但是并没有第二步，也就是没有把不同channel的特征融合起来，而是concatenate起来。这时的输出channel与输出是一样的，后续很可能还要跟从1*1卷积，从而等价于可分离卷积。

4 更进一步，当分组数量 ![[公式]](https://www.zhihu.com/equation?tex=G) 等于输入通道数量，卷积核的宽高等于输入的宽高，那么输出就是 ![[公式]](https://www.zhihu.com/equation?tex=G%2A1%2A1) 的特征图，就类似于每个map输出一个值，此时称之为**Global Depthwise Convolution（GDC），**可以看成是**全局加权池化**，与 **Global Average Pooling（GAP）** 的不同之处在于，GDC **给每个位置赋予了可学习的权重**（对于已对齐的图像这很有效，比如人脸，中心位置和边界位置的权重自然应该不同），而GAP每个位置的权重相同，全局取个平均，如下图所示：

![img](https://pic3.zhimg.com/80/v2-b98bb36ee846214eee37b2698277337e_hd.jpg)

应用:MobileFaceNet,使用了全局加权池化代替了全局平均池化，是对mobilenetV2的升级

## 空洞卷积

DilatedDilated convolution：空洞卷积或者扩张卷积（同 Atrous convolutionconvolution）

Dialted convolution最先在使用图像分割领域，图像输入到CNN中提取特征（如FCN），FCN先像传统的CNN那样对图像做卷积再pooling，降低图像尺寸的同时增大感受野，但是由于图像分割预测是pixel-wise的输出，所以要将pooling后较小的图像尺寸upsampling到原始的图像尺寸进行预测（upsampling一般采用deconv反卷积操作，deconv可参见知乎答案[如何理解深度学习中的deconvolution networks？](https://www.zhihu.com/question/43609045/answer/132235276)）总结来说：包括pooling操作增加感受野和Upsampling扩大至原图尺寸。但是此过程中会由于Pooling操作产生信息的损失，不利于分割或者目标检测。Dilated convolution就是为了在不是用pooling操作损失信息也能增加感受野。 Dilated 示意图如下：

![img](https://pic1.zhimg.com/80/v2-c3f2f238b64761313174b7ad463d6460_hd.jpg)

Dialted示意图 概念介绍：空洞卷积的rate，代表传统卷积核的相邻之间插入rate-1个空洞数。当rate=1时，相当于传统的卷积核。 从两个角度考虑空洞卷积： （1）从kernel（卷积核）角度：相当于在标准概念的kernel（卷积核）中，相邻点之间添加rate-1个0，然后使用扩张后的kernel（卷积核）与原图进行卷积。如下图rate=2，相当于标准的3*3卷积核变为5*5卷积核，每一行中间添加2-1个0 （2）从原图角度：使用标准概念的kernel（卷积核）在原图中每隔rate-1进行像素点卷积采样。如下图rate=2，在原图中每隔rate-1进行卷积。

![img](https://pic2.zhimg.com/80/v2-83660225276c455922c98f045087269d_hd.jpg)

Dilated convolution rate=2，kernel（3x3） F*F的Feature map经过kernel size(k),padding(p), stride(s), rate(r) Dilated convolution卷积输出的大小: 使用标准卷积的计算为：

![img](https://pic1.zhimg.com/80/v2-cca82dabc90953003ab62977ae988818_hd.png)

标准卷积计算方式 使用Dilated卷积的计算公式为：

![img](https://pic1.zhimg.com/80/v2-17095e544bbe1dbf97cb9d7398d8a2f8_hd.png)

Dilated卷积计算方式 例子：7*7的feature map，kernel size = 3, padding = 0,stride = 1,rate =2 标准卷积后大小F为(7-3+0)/1+1 = 5，Dilated卷积后大小F为[7-(3+2*1)+0]/1+1=3

## 转置卷积

Transposed convolution (deconvolution "bad name") 转置卷积不是“反卷积”

https://blog.csdn.net/u013250416/article/details/78247818

