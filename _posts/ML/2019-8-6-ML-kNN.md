---
layout: post
title: 统计学习方法之K-NN
category: 机器学习
description: 统计学习方法
---

是一种基本的分类和回归方法，目前仅考虑分类问题。本文记录k近邻算法，以及该算法的模型及三个基本要素，最后是实现方法-kd树：包括构造kd树和搜索kd树的算法

## k 近邻算法
给定一个训练数据集，对新的输入实例，在训练数据集中找到与该实例最邻近的k个实例，这k个实例的多数属于某个类，就把该输入分为那个类。

## k近邻模型
模型的三个要素-距离度量，k值选择，分类决策规则
**距离度量**
欧式距离，
L_p 距离，当p等于2时，就是欧式距离，当p=1 时，就是曼哈顿距离。
**k值的选择**
k较小，模型复杂，容易过拟合
k较大，模型简单。
实际应用中，要选择最优的k，通常采用交叉验证法选取。
**分类决策规则**
就是多数表决，等价于经验风险最小化。
## kd树
要对训练数据进行快速k近邻搜索，
最简单的是进行线性搜索，计算耗时，不可行
考虑特殊的数据结构存储训练数据，，以减少计算距离的次数。
**构造kd树**
对k维空间中的实例点进行存储以便对其进行快速检索的树形结构，二叉树，每个节点存一个实例，
**搜索kd树**
假设空间维度是k，实例数是N，那么搜索的事件复杂度是log(N),，因为是树形结构。
适用于N远大于k时。


